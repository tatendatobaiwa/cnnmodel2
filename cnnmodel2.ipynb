{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ***SIMPLE CNN MODEL BUILD FOR LUNG CANCER IMAGING***"
      ],
      "metadata": {
        "id": "QlaQ4nr_yhw1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1: Mount Drive**"
      ],
      "metadata": {
        "id": "8B-3KEZEypc8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ViKWf2N6yg8I",
        "outputId": "2820c0d7-c423-4d45-b68f-abd6d1df102d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2: Create Directories in Drive**"
      ],
      "metadata": {
        "id": "St-4OKQZyt6s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 3: Install Dependenices**"
      ],
      "metadata": {
        "id": "FEmy_QBs3odT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U tensorflow==2.13.0\n",
        "!pip install -q -U tensorflow-addons==0.23.0\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import sys\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "project_path = '/content/drive/MyDrive/cnn_project'\n",
        "sys.path.append(project_path)"
      ],
      "metadata": {
        "id": "LU4bCKlz33CN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Mini Step 3a: Verify Fixes**"
      ],
      "metadata": {
        "id": "9Gj1wK6r3_x1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "\n",
        "print(f\"TensorFlow version: {tf.__version__}\")\n",
        "print(f\"TensorFlow Addons version: {tfa.__version__}\")"
      ],
      "metadata": {
        "id": "jfOxvHnv39_V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 4: Use a script to Load and Preprocess Data**"
      ],
      "metadata": {
        "id": "34UkySdn4Ei2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class DataProcessor:\n",
        "    def __init__(self, base_path=\"/content/drive/MyDrive/cnn_project\"):\n",
        "        self.base_path = Path(base_path)\n",
        "        self.train_path = self.base_path / \"data/raw/train\"\n",
        "        self.test_path = self.base_path / \"data/raw/test\"\n",
        "\n",
        "    def load_images(self, directory, target_size=(256, 256), use_clahe=False):\n",
        "        images = []\n",
        "        labels = []\n",
        "        class_names = ['benign', 'malignant', 'normal']\n",
        "        for label, class_name in enumerate(class_names):\n",
        "            class_dir = directory / class_name\n",
        "            for img_path in class_dir.glob('*'):\n",
        "                if img_path.suffix.lower() in ('.png', '.jpg', '.jpeg'):\n",
        "                    img = cv2.imread(str(img_path), cv2.IMREAD_GRAYSCALE)\n",
        "                    if img is None:\n",
        "                        print(f\"Warning: Unable to load image {img_path}\")\n",
        "                        continue\n",
        "                    if use_clahe:\n",
        "                        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
        "                        img = clahe.apply(img)\n",
        "                    img = cv2.resize(img, target_size)\n",
        "                    images.append(img)\n",
        "                    labels.append(label)\n",
        "        return np.array(images), np.array(labels)\n",
        "\n",
        "    def create_generators(self, batch_size=32, use_clahe=False):\n",
        "        # Load images and normalize to [0, 1]\n",
        "        X_train, y_train = self.load_images(self.train_path, use_clahe=use_clahe)\n",
        "        X_train = X_train[..., np.newaxis] / 255.0\n",
        "\n",
        "        # Split into training and validation sets (stratified)\n",
        "        X_train, X_val, y_train, y_val = train_test_split(\n",
        "            X_train, y_train, test_size=0.2, stratify=y_train, random_state=42\n",
        "        )\n",
        "\n",
        "        # Data augmentation for training\n",
        "        train_datagen = ImageDataGenerator(\n",
        "            rotation_range=20,\n",
        "            width_shift_range=0.2,\n",
        "            height_shift_range=0.2,\n",
        "            shear_range=0.2,\n",
        "            zoom_range=0.2,\n",
        "            horizontal_flip=True,\n",
        "            brightness_range=[1.0, 1.5],\n",
        "            fill_mode='nearest'\n",
        "        )\n",
        "        val_datagen = ImageDataGenerator()  # No augmentation for validation\n",
        "\n",
        "        train_generator = train_datagen.flow(X_train, y_train, batch_size=batch_size, shuffle=True)\n",
        "        val_generator = val_datagen.flow(X_val, y_val, batch_size=batch_size, shuffle=False)\n",
        "        return train_generator, val_generator, X_val, y_val\n",
        "\n",
        "    def show_augmented_images(self, generator, n_images=5, gamma=1.0):\n",
        "        \"\"\"\n",
        "        Visualizes a few augmented images.\n",
        "        - gamma: a factor for gamma correction (set gamma < 1 to brighten).\n",
        "        \"\"\"\n",
        "        images, labels = next(generator)\n",
        "        plt.figure(figsize=(15, 3))\n",
        "        for i in range(n_images):\n",
        "            img = images[i].squeeze()\n",
        "            if gamma != 1.0:\n",
        "                img = np.power(img, 1.0/gamma)\n",
        "            plt.subplot(1, n_images, i+1)\n",
        "            plt.imshow(img, cmap='gray', vmin=0, vmax=1)\n",
        "            plt.title(f\"Label: {labels[i]}\")\n",
        "            plt.axis('off')\n",
        "        plt.tight_layout()\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "BngS1vGK4FOm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 5: Model Development**"
      ],
      "metadata": {
        "id": "obyWBZHw4HZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def create_model(input_shape=(256, 256, 1), num_classes=3):\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.MaxPooling2D(2, 2),\n",
        "\n",
        "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.MaxPooling2D(2, 2),\n",
        "\n",
        "        tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.MaxPooling2D(2, 2),\n",
        "\n",
        "        tf.keras.layers.GlobalAveragePooling2D(),\n",
        "        tf.keras.layers.Dense(256, activation='relu'),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "INVNdpft4UAh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 6: Model Training**"
      ],
      "metadata": {
        "id": "9IWDOW6s4eNI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "import matplotlib.pyplot as plt\n",
        "from utils.data_processing import DataProcessor\n",
        "from utils.model import create_model\n",
        "\n",
        "def train_model(model, train_generator, val_generator, epochs=50, checkpoint_path='best_model.h5'):\n",
        "    # Set up callbacks for robust training\n",
        "    early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose=1)\n",
        "    checkpoint = ModelCheckpoint(checkpoint_path, monitor='val_loss', save_best_only=True, verbose=1)\n",
        "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6, verbose=1)\n",
        "    callbacks = [early_stop, checkpoint, reduce_lr]\n",
        "\n",
        "    history = model.fit(\n",
        "        train_generator,\n",
        "        validation_data=val_generator,\n",
        "        epochs=epochs,\n",
        "        callbacks=callbacks,\n",
        "        verbose=1\n",
        "    )\n",
        "    return history\n",
        "\n",
        "def plot_training_history(history):\n",
        "    # Plot loss and accuracy over epochs\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['loss'], label='Train Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Val Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "    plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Initialize the data processor and generators\n",
        "    processor = DataProcessor()\n",
        "    train_gen, val_gen, X_val, y_val = processor.create_generators(batch_size=32)\n",
        "\n",
        "    # Create the model\n",
        "    model = create_model(input_shape=(256, 256, 1), num_classes=3)\n",
        "\n",
        "    # Train the model\n",
        "    history = train_model(model, train_gen, val_gen, epochs=50, checkpoint_path='best_model.h5')\n",
        "\n",
        "    # Plot training history\n",
        "    plot_training_history(history)\n",
        "\n",
        "    # Optionally, save the final model\n",
        "    model.save('final_model.h5')"
      ],
      "metadata": {
        "id": "30Q6MoyY4ri5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 7: Model Evaluation**"
      ],
      "metadata": {
        "id": "-TBkwQwV4s6Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "def evaluate_model(model, X_val, y_val, class_names=['benign', 'malignant', 'normal']):\n",
        "    # Generate predictions and convert to class indices\n",
        "    y_pred = model.predict(X_val)\n",
        "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "    # Print classification report\n",
        "    print(\"Classification Report:\")\n",
        "    print(classification_report(y_val, y_pred_classes, target_names=class_names))\n",
        "\n",
        "    # Plot confusion matrix\n",
        "    cm = confusion_matrix(y_val, y_pred_classes)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=class_names, yticklabels=class_names)\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.show()\n",
        "\n",
        "    # Print per-class and overall accuracy\n",
        "    class_acc = {}\n",
        "    for i, class_name in enumerate(class_names):\n",
        "        mask = (y_val == i)\n",
        "        class_acc[class_name] = np.mean(y_pred_classes[mask] == y_val[mask])\n",
        "    print(\"Class-wise Accuracy:\")\n",
        "    for class_name, acc in class_acc.items():\n",
        "        print(f\"{class_name}: {acc:.2%}\")\n",
        "    overall_acc = accuracy_score(y_val, y_pred_classes)\n",
        "    print(f\"Overall Accuracy: {overall_acc:.2%}\")"
      ],
      "metadata": {
        "id": "1v25RPLa40hp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the evaluation function\n",
        "from utils.evaluate import evaluate_model\n",
        "evaluate_model(model, X_val, y_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "WW62T6mc5Y0B",
        "outputId": "c5e28947-a6f1-4af9-a35e-33bb69b87aeb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'utils'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-4292088e6bbc>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'utils'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 8: Implementation of Explainable AI (Grad-CAM)**"
      ],
      "metadata": {
        "id": "TxTHY0OH438x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def grad_cam(model, img_array, layer_name='conv2d_2', class_index=None):\n",
        "    # Create a model that outputs the target convolutional layer and predictions\n",
        "    grad_model = tf.keras.models.Model(\n",
        "        [model.inputs], [model.get_layer(layer_name).output, model.output]\n",
        "    )\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        conv_outputs, predictions = grad_model(img_array)\n",
        "        if class_index is None:\n",
        "            class_index = tf.argmax(predictions[0])\n",
        "        loss = predictions[:, class_index]\n",
        "\n",
        "    # Compute gradients and perform global pooling\n",
        "    grads = tape.gradient(loss, conv_outputs)\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "\n",
        "    conv_outputs = conv_outputs[0]\n",
        "    heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]\n",
        "    heatmap = tf.squeeze(heatmap).numpy()\n",
        "    heatmap = np.maximum(heatmap, 0)\n",
        "    heatmap /= np.max(heatmap) if np.max(heatmap) != 0 else 1\n",
        "\n",
        "    # Resize the heatmap and apply the color map\n",
        "    heatmap = cv2.resize(heatmap, (img_array.shape[2], img_array.shape[1]))\n",
        "    heatmap = np.uint8(255 * heatmap)\n",
        "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
        "\n",
        "    # Superimpose the heatmap on the original image (converted from grayscale)\n",
        "    img = np.uint8(255 * img_array[0].squeeze())\n",
        "    img_bgr = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
        "    superimposed_img = cv2.addWeighted(img_bgr, 0.6, heatmap, 0.4, 0)\n",
        "    return superimposed_img\n",
        "\n",
        "def visualize_explanations(model, X_val, y_val, num_samples=3):\n",
        "    class_names = ['benign', 'malignant', 'normal']\n",
        "    indices = np.random.choice(len(X_val), num_samples, replace=False)\n",
        "    plt.figure(figsize=(15, 5 * num_samples))\n",
        "    for i, idx in enumerate(indices, 1):\n",
        "        img = X_val[idx]\n",
        "        true_label = class_names[y_val[idx]]\n",
        "        pred = model.predict(np.expand_dims(img, axis=0))\n",
        "        pred_class = class_names[np.argmax(pred)]\n",
        "        explanation = grad_cam(model, np.expand_dims(img, axis=0))\n",
        "\n",
        "        plt.subplot(num_samples, 2, 2 * i - 1)\n",
        "        plt.imshow(img.squeeze(), cmap='gray')\n",
        "        plt.title(f\"True: {true_label}\\nPred: {pred_class}\")\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(num_samples, 2, 2 * i)\n",
        "        plt.imshow(explanation)\n",
        "        plt.title(\"Grad-CAM Explanation\")\n",
        "        plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "e78ski0J4-5B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize model explanations\n",
        "\n",
        "from utils.xai import visualize_explanations\n",
        "visualize_explanations(model, X_val, y_val, num_samples=3)"
      ],
      "metadata": {
        "id": "_uZ4z0Gj5oUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 9: Running the Project**"
      ],
      "metadata": {
        "id": "62w20OKE5FAz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "project_path = '/content/drive/MyDrive/cnnprojectfinal'\n",
        "if project_path not in sys.path:\n",
        "    sys.path.append(project_path)"
      ],
      "metadata": {
        "id": "W9kqKALo5Jba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 10: Testing Model Accuracy on Test images**"
      ],
      "metadata": {
        "id": "ddo_AQKV5OhK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_test_images(test_dir, target_size=(256, 256)):\n",
        "    test_dir = Path(test_dir)\n",
        "    images = []\n",
        "    image_paths = list(test_dir.glob('*'))\n",
        "    for img_path in image_paths:\n",
        "        if img_path.suffix.lower() in ('.png', '.jpg', '.jpeg'):\n",
        "            img = cv2.imread(str(img_path), cv2.IMREAD_GRAYSCALE)\n",
        "            if img is not None:\n",
        "                img = cv2.resize(img, target_size)\n",
        "                images.append(img[..., np.newaxis] / 255.0)\n",
        "    return np.array(images), image_paths\n",
        "\n",
        "# Usage:\n",
        "test_images, test_paths = load_test_images(\"/content/drive/MyDrive/cnnprojectfinal/data/raw/test\")\n",
        "predictions = model.predict(test_images)"
      ],
      "metadata": {
        "id": "dM4D9DcP6C3S"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}